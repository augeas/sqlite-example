{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations - Practice Challenge\n",
    "\n",
    "Is [Charles Minard's](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.title.html) chart of [Napoleon's retreat from Moscow](http://www.masswerk.at/minard/) the best infographic ever? You're going to practice using a number of visualization libraries. -Make sure you've installed [Seaborn](https://seaborn.pydata.org/), [ggplot](http://ggplot.yhathq.com/), [Folium](https://folium.readthedocs.io/en/latest/) and even the dreaded [matplotlib](https://matplotlib.org/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import folium\n",
    "from ggplot import *\n",
    "import matplotlib.dates as md\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll get some of the General Election data we've played with before back into Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ge_2010_url = 'https://raw.githubusercontent.com/augeas/undergrad-python-exercises/master/jsondata/ge_2010.json'\n",
    "ge_2010 = pd.read_json(requests.get(ge_2010_url).text)\n",
    "\n",
    "ge_2015_url = 'https://raw.githubusercontent.com/augeas/undergrad-python-exercises/master/jsondata/ge_2015.json'\n",
    "ge_2015 = pd.read_json(requests.get(ge_2015_url).text)\n",
    "\n",
    "ge_2017_url = 'https://raw.githubusercontent.com/augeas/undergrad-python-exercises/master/jsondata/ge_2017.json'\n",
    "ge_2017 = pd.read_json(requests.get(ge_2017_url).text)\n",
    "\n",
    "ge_all_url = 'https://raw.githubusercontent.com/augeas/undergrad-python-exercises/master/jsondata/pandas_ge_data.json'\n",
    "ge_all = pd.read_json(requests.get(ge_all_url).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build a dictionary to get party names by their abbreviations, we don't use 2015 to do this, it was a bit odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def party_abbrev(df):\n",
    "    holds = df['outcome'].str.lower() == 'seat held'\n",
    "    parties = dict(zip(df[holds]['member_party'].unique(),df[holds]['incumbent_party'].unique()))\n",
    "    return parties\n",
    "\n",
    "p_2010 = party_abbrev(ge_2010)\n",
    "p_2017 = party_abbrev(ge_2017)\n",
    "\n",
    "parties = p_2010.copy()\n",
    "parties.update(p_2017)\n",
    "\n",
    "parties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a dictionary whose keys are party abbreviations, the values are the net changes in seats for that party. It takes a dataframe, one of *ge_2010*, *ge_2015* or *ge_2017*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def net_seats(df):\n",
    "    gains = (df['outcome'].str.lower() == 'seat gain') | (df['outcome'].str.lower() == 'gain')\n",
    "    agg_gains = df[gains].groupby('member_party').aggregate({'member_party':'count'})\n",
    "    agg_losses = df[gains].groupby('incumbent_party').aggregate({'incumbent_party':'count'})\n",
    "    changes = {}\n",
    "    for k in parties.keys():\n",
    "        try:\n",
    "            gain = agg_gains['member_party'][k]\n",
    "        except:\n",
    "            gain = 0\n",
    "        try:\n",
    "            loss = agg_losses['incumbent_party'][parties[k]]\n",
    "        except:\n",
    "            loss = 0\n",
    "        change = gain - loss\n",
    "        if change:\n",
    "            changes[k] = gain - loss\n",
    "    # Merge the Labour and Labour Co-op parties.\n",
    "    changes['L'] += changes.get('L Co-op',0)\n",
    "    changes.pop('L Co-op',None)\n",
    "    return changes                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: A Simple Bar Chart\n",
    "\n",
    "Take a look at this [Seaborn bar-chart example](https://seaborn.pydata.org/examples/color_palettes.html). Plot the net change in seats for each party in the 2017 election as a bar chart. The party abbreviations should be on the x-axis. You'll need to create a list for the y-axis data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "net_gains_2017 = net_seats(ge_2017)\n",
    "party_list = list(net_gains_2017.keys())\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it's the Titanic data set again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic = pd.read_csv(titanic_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Faceted Historgrams\n",
    "\n",
    "Here's a slightly dull use of Seaborn's [faceted histograms](https://seaborn.pydata.org/examples/faceted_histogram.html). There are four histograms of the Titanic passesngers fares, according to whether they were male or female and whether they survived. Produce a set of six faceted histograms for the passengers who survived. The three passenger classes should vary on the x-axis, with the passenger's gender of the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fares = sns.FacetGrid(titanic, row=\"Survived\", col=\"Sex\", margin_titles=True)\n",
    "bins = np.linspace(0, 200, 10)\n",
    "fares.map(plt.hist, \"Fare\", bins=bins, lw=0)\n",
    "survivors = titanic['Survived'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bins = np.linspace(0, 80, 10)\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next bit, we'll use the [Wayback Machine API](https://archive.org/help/wayback_api.php) to grab data from the [2016 Jill Stein recount crowd-funder](https://www.jill2016.com/recount). The next two cells will take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rec_req = requests.get(\"https://web.archive.org/cdx/search/cdx?url=jillstein.nationbuilder.com/recount&output=json\")\n",
    "timestamps = [snapshot[1] for snapshot in rec_req.json()[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_val(soup,goal=False):\n",
    "    # https://twitter.com/thepracticaldev/status/710156980535558144\n",
    "    try:\n",
    "        txt = soup.find(**{'class_':('bar-text','bar-goal')[goal]}).text\n",
    "        return float(''.join(re.search('[0-9.,]+',txt).group().split(','))) / 1.0E6\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_vals(timestamp):\n",
    "    req = requests.get(\"http://web.archive.org/web/\"+timestamp+\"/https://jillstein.nationbuilder.com/recount\")\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    return (parse_val(soup),parse_val(soup,goal=True))\n",
    "    \n",
    "rec_data = [get_vals(t) for t in timestamps if t[0:4] == '2016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"rec_data\" is a list of tuples, the first item is the ammount raised in millions of Dollars, the second is the goal ammount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rec_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raised, goal = zip(*filter(lambda x: x, rec_data))\n",
    "rec_times = [datetime.strptime(t, '%Y%m%d%H%M%S') for t in timestamps if t[0:4] == '2016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the list into separate ones for the raised and goal ammounts, \"rec_times\" is a list of Python [Datetime](https://docs.python.org/3/library/datetime.html) objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rec_times[0:5], '\\n', raised[0:5], '\\n', goal[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We *can* use Matplotlib to plot this, but as you can see, it's a bit of a production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "fmt = md.DateFormatter('%m/%d %H:%M')\n",
    "ax.xaxis.set_major_formatter(fmt)\n",
    "plt.xticks(rotation=25)\n",
    "raised_line, = plt.plot(rec_times, raised, marker='*')\n",
    "ax.set_xlabel('Time Retrieved')\n",
    "ax.set_ylabel('Amount in Millions of $')\n",
    "goal_line, = plt.plot(rec_times, goal)\n",
    "plt.legend([raised_line, goal_line], ['raised','goal'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Time Series Using ggplot\n",
    "\n",
    "The last figure can be done in three lines with ggplot.\n",
    "\n",
    "- Use Pandas [https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_items.html](from_items) function to build a dataframe from the three lists with columns called \"time\", \"raised\" and \"goal\".\n",
    "- Read the \"trends over time\" section of this [ggplot blog-post](http://blog.yhat.com/posts/aggregating-and-plotting-time-series-in-python.html). You'll neeed the Pandas [melt function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html).\n",
    "- You'll also need the \"ylab\" function mentioned in [this post](http://blog.yhat.com/posts/ggplot-for-python.html) to reproduce the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to UK politics. Here's a hand [list of constituency locations](https://www.doogal.co.uk/ElectoralConstituencies.php). We can use Pandas [merge function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) to get a dataframe of locations and winning parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consituency_url = 'https://www.doogal.co.uk/ElectoralConstituenciesCSV.ashx'\n",
    "consituencies = pd.read_csv(consituency_url)\n",
    "\n",
    "def seat_winners(yr):\n",
    "    wins = (ge_all['Year']==yr) & (ge_all['Majority Party'].notnull())\n",
    "    return ge_all[wins]\n",
    "\n",
    "def seat_locations(yr):\n",
    "    return pd.merge(seat_winners(yr), consituencies, left_on='Constituency', right_on='Constituency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "party_colours = {'Conservative':'blue', 'Labour':'red','Lib Dem':'beige', 'Democratic Unionist Party':'pink',\n",
    "    'Sinn Fein':'darkgreen', 'Independent':'gray', 'Scottish National Party':'orange', 'Plaid Cymru':'purple',\n",
    "    'Green':'green', 'Speaker':'lightgray'}\n",
    "\n",
    "seats_2017 = seat_locations(2017)[['Party','Latitude','Longitude']]\n",
    "\n",
    "seats_2017[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: UK Election Map Using Folium\n",
    "Complete the for-loop over the \"seats_2017\" dataframe's [itertuples method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.itertuples.html). Call \"help\" on Folium's \"folium.Marker\" and \"folium.Icon\" classes to add a suitably coloured marker to \"seat map\". There's an example in the SQL challenge notebook. Let's hope the DUP don't mind being coloured [pink](https://www.pinknews.co.uk/2017/06/12/meet-the-dup-homophobes-who-now-hold-the-keys-to-power-in-the-uk/)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_centre = [seats_2017['Latitude'].mean(), seats_2017['Longitude'].mean()]\n",
    "\n",
    "seat_map = folium.Map(location=map_centre, zoom_start=5)\n",
    "\n",
    "for row in seat_locations(2017)[['Party','Latitude','Longitude']].itertuples():\n",
    "    pass\n",
    "    # Your code here.\n",
    "    \n",
    "seat_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how vote share changes in constituencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def consituency_df(con):\n",
    "    cons = ge_all['Constituency'] == con\n",
    "    return ge_all[cons]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need quite a bit of [Pandas magick](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html) to get this datframe into a useable form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edgbaston = consituency_df('Birmingham, Edgbaston')[['Party','Share of Vote','Year']]\n",
    "edgbaston[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_edgbaston = edgbaston.groupby(['Year','Party']).sum().unstack(level=1)['Share of Vote']\n",
    "flat_edgbaston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Stacked Bars With Pandas and Matplotlib\n",
    "\n",
    "Use the \"flat_edgbaston\" dataframe to plot the evolving vote share in Edgbaston, Birmingham as a stacked bar chart. The [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html) will help. Use the \"figsize\" parameter to ensure the graph is a decent size. The [legend and key](https://matplotlib.org/users/legend_guide.html) should be in a sensible place. Give your chart a [title](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.title.html) too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# Your code here.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
